{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator # inport api\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "\n",
    "\n",
    "data_dir = \"/home/images_training_rev1/\"\n",
    "label_dir = \"/home/5-class-inorder.csv\"\n",
    "\n",
    "label=pd.read_csv(label_dir)\n",
    "# label = xls_file.parse('edge-on_smooth')\n",
    "index1=label['GalaxyID']\n",
    "# print(index1)\n",
    "# print(len(index1))\n",
    "\n",
    "label_list=label['class']\n",
    "label_list=list(label_list)\n",
    "image_list=[]\n",
    "\n",
    "for i in range(len(index1)):\n",
    "    image_list.append(data_dir+str(index1[i])+'.jpg')\n",
    "print(\"image_list长度：%d\"%len(image_list))\n",
    "\n",
    "temp = np.array([image_list, label_list])\n",
    "temp = temp.transpose()\n",
    "# print(temp)\n",
    "# np.random.shuffle(temp)\n",
    "    \n",
    "image_list = list(temp[:, 0])\n",
    "label_list = list(temp[:, 1])\n",
    "label_list = [round(float(i)) for i in label_list] \n",
    "\n",
    "image_c, image_id, label_trans = [],[],[]\n",
    "idd = 0\n",
    "######################################################\n",
    "#在下面指定各类别是inlier||outlier以及他们的数量 \n",
    "#0 smooth : 8437\n",
    "# 1 1betwe:8069\n",
    "# 2 cigar:579  * 12 = 6948\n",
    "# 3 edge: 3903  * 2 = 7806\n",
    "# 4 spiral:7806\n",
    "#####################################################\n",
    "smooth_num = 546\n",
    "smooth_label = 1\n",
    "\n",
    "between_num = 546\n",
    "between_label = 1\n",
    "\n",
    "cigar_num = 6948\n",
    "cigar_label = 0\n",
    "\n",
    "edge_num = 7806\n",
    "edge_label = 0\n",
    "\n",
    "spiral_num = 546\n",
    "spiral_label = 1\n",
    "\n",
    "smooth_num_tmp = between_num_tmp = cigar_num_tmp = edge_num_tmp = spiral_num_tmp = 0\n",
    "for i in range(len(image_list)):\n",
    "    if label_list[i] == 0 and smooth_num_tmp  <smooth_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(smooth_label)\n",
    "        smooth_num_tmp += 1\n",
    "     \n",
    "    \n",
    "    if label_list[i] == 1 and between_num_tmp <between_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(between_label)\n",
    "        between_num_tmp += 1\n",
    "    \n",
    "    if label_list[i] == 2 and cigar_num_tmp <cigar_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.ROTATE_90)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.ROTATE_180)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.ROTATE_270)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.ROTATE_90)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.ROTATE_180)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.ROTATE_270)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.ROTATE_90)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.ROTATE_180)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.ROTATE_270)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    if label_list[i] == 3 and edge_num_tmp <edge_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(edge_label)\n",
    "        edge_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(edge_label)\n",
    "        edge_num_tmp += 1\n",
    "\n",
    "    \n",
    "    if label_list[i] == 4 and spiral_num_tmp <spiral_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(spiral_label)\n",
    "        spiral_num_tmp += 1\n",
    "    \n",
    "     \n",
    "        \n",
    "print(smooth_num_tmp , between_num_tmp , cigar_num_tmp , edge_num_tmp , spiral_num_tmp)\n",
    "\n",
    "dictory = dict(zip(image_id, label_trans))     \n",
    "image_c = np.array(image_c)\n",
    "image_c = image_c/255\n",
    "image_c = image_c.reshape(len(label_trans),64,64,3)\n",
    "    \n",
    "    \n",
    "    \n",
    "# image_c = np.array(image_c)\n",
    "# image_c = image_c/255\n",
    "# image_c = image_c.reshape(len(la),64,64,1)   \n",
    "# datagen.fit(image_c)            \n",
    "print(np.array(image_c).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/zouzq/.local/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:336: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_list长度：28793\n",
      "16872 0 579 1295 0\n",
      "(18746, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator # inport api\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "\n",
    "\n",
    "data_dir = \"/home/images_training_rev1/\"\n",
    "label_dir = \"/home/5-class-inorder.csv\"\n",
    "\n",
    "label=pd.read_csv(label_dir)\n",
    "# label = xls_file.parse('edge-on_smooth')\n",
    "index1=label['GalaxyID']\n",
    "# print(index1)\n",
    "# print(len(index1))\n",
    "\n",
    "label_list=label['class']\n",
    "label_list=list(label_list)\n",
    "image_list=[]\n",
    "\n",
    "for i in range(len(index1)):\n",
    "    image_list.append(data_dir+str(index1[i])+'.jpg')\n",
    "print(\"image_list长度：%d\"%len(image_list))\n",
    "\n",
    "temp = np.array([image_list, label_list])\n",
    "temp = temp.transpose()\n",
    "# print(temp)\n",
    "# np.random.shuffle(temp)\n",
    "    \n",
    "image_list = list(temp[:, 0])\n",
    "label_list = list(temp[:, 1])\n",
    "label_list = [round(float(i)) for i in label_list] \n",
    "\n",
    "image_c, image_id, label_trans = [],[],[]\n",
    "idd = 0\n",
    "######################################################\n",
    "#在下面指定各类别是inlier||outlier以及他们的数量 \n",
    "#0 smooth : 8437 * 2 =16874\n",
    "# 1 1betwe:8069\n",
    "# 2 cigar:579  \n",
    "# 3 edge: 3903 \n",
    "# 4 spiral:7806\n",
    "#####################################################\n",
    "smooth_num = 16874\n",
    "smooth_label = 0\n",
    "\n",
    "between_num = 0\n",
    "between_label = 1\n",
    "\n",
    "cigar_num = 579\n",
    "cigar_label = 1\n",
    "\n",
    "edge_num = 1295\n",
    "edge_label = 1\n",
    "\n",
    "spiral_num = 0\n",
    "spiral_label = 1\n",
    "\n",
    "smooth_num_tmp = between_num_tmp = cigar_num_tmp = edge_num_tmp = spiral_num_tmp = 0\n",
    "for i in range(len(image_list)):\n",
    "    if label_list[i] == 0 and smooth_num_tmp  <smooth_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(smooth_label)\n",
    "        smooth_num_tmp += 1\n",
    "        \n",
    "        image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(smooth_label)\n",
    "        smooth_num_tmp += 1\n",
    "     \n",
    "    \n",
    "    if label_list[i] == 1 and between_num_tmp <between_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(between_label)\n",
    "        between_num_tmp += 1\n",
    "    \n",
    "    if label_list[i] == 2 and cigar_num_tmp <cigar_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(cigar_label)\n",
    "        cigar_num_tmp += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    if label_list[i] == 3 and edge_num_tmp <edge_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(edge_label)\n",
    "        edge_num_tmp += 1\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    if label_list[i] == 4 and spiral_num_tmp <spiral_num:\n",
    "        image = Image.open(image_list[i])\n",
    "#         image = image.convert('L')\n",
    "        img_width = random.randint(170,240)\n",
    "        CenterCrop = transforms.CenterCrop((img_width,img_width))\n",
    "        image = CenterCrop(image)\n",
    "        image = image.resize((80,80))\n",
    "        image = image.resize((64,64))\n",
    "        \n",
    "        image_c.append(np.array(image))\n",
    "        image_id.append(idd)\n",
    "        idd += 1\n",
    "#         label_trans.append(label_list[i])\n",
    "        label_trans.append(spiral_label)\n",
    "        spiral_num_tmp += 1\n",
    "    \n",
    "     \n",
    "        \n",
    "print(smooth_num_tmp , between_num_tmp , cigar_num_tmp , edge_num_tmp , spiral_num_tmp)\n",
    "\n",
    "dictory = dict(zip(image_id, label_trans))     \n",
    "image_c = np.array(image_c)\n",
    "image_c = image_c/255\n",
    "image_c = image_c.reshape(len(label_trans),64,64,3)\n",
    "    \n",
    "    \n",
    "    \n",
    "# image_c = np.array(image_c)\n",
    "# image_c = image_c/255\n",
    "# image_c = image_c.reshape(len(la),64,64,1)   \n",
    "# datagen.fit(image_c)            \n",
    "print(np.array(image_c).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.get_state()\n",
    "np.random.shuffle(image_c)\n",
    "np.random.set_state(state)\n",
    "np.random.shuffle(label_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DATA PROCESS TIME: 2.384185791015625e-07\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 64, 128)  6272        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 128)          0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 128)          0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1, 128)    0           global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1, 1, 16)     2064        reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1, 1, 128)    2176        dense_21[0][0]                   \n",
      "                                                                 dense_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1, 1, 128)    0           dense_22[0][0]                   \n",
      "                                                                 dense_22[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 1, 128)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 64, 64, 128)  0           conv2d_41[0][0]                  \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64, 64, 1)    0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 64, 64, 1)    0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 2)    0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 64, 64, 1)    98          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 64, 64, 128)  0           multiply_1[0][0]                 \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 32, 32, 128)  0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 64)   131136      max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 64)           0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1, 64)     0           global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1, 1, 8)      520         reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1, 1, 64)     576         dense_23[0][0]                   \n",
      "                                                                 dense_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1, 1, 64)     0           dense_24[0][0]                   \n",
      "                                                                 dense_24[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 1, 64)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 32, 32, 64)   0           conv2d_43[0][0]                  \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 32, 32, 1)    0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 32, 32, 1)    0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 2)    0           lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 1)    98          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 32, 32, 64)   0           multiply_3[0][0]                 \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 16, 16, 64)   0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 32)   18464       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 32)           0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 32)           0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1, 32)     0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1, 32)     0           global_max_pooling2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1, 1, 4)      132         reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1, 1, 32)     160         dense_25[0][0]                   \n",
      "                                                                 dense_25[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1, 1, 32)     0           dense_26[0][0]                   \n",
      "                                                                 dense_26[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 1, 32)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 16, 16, 32)   0           conv2d_45[0][0]                  \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16, 16, 1)    0           multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16, 16, 1)    0           multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 2)    0           lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 1)    98          concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 16, 16, 32)   0           multiply_5[0][0]                 \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 8, 8, 32)     0           multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 16)     4624        max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 16)           0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_4 (GlobalM (None, 16)           0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1, 16)     0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1, 16)     0           global_max_pooling2d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1, 1, 2)      34          reshape_11[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1, 1, 16)     48          dense_27[0][0]                   \n",
      "                                                                 dense_27[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1, 1, 16)     0           dense_28[0][0]                   \n",
      "                                                                 dense_28[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1, 1, 16)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 8, 8, 16)     0           conv2d_47[0][0]                  \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 8, 8, 1)      0           multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 8, 8, 1)      0           multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 2)      0           lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 1)      98          concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 8, 8, 16)     0           multiply_7[0][0]                 \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 4, 4, 16)     0           multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 8)      520         max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 8)            0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_5 (GlobalM (None, 8)            0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 1, 8)      0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 1, 8)      0           global_max_pooling2d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1, 1, 1)      9           reshape_13[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1, 1, 8)      16          dense_29[0][0]                   \n",
      "                                                                 dense_29[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1, 1, 8)      0           dense_30[0][0]                   \n",
      "                                                                 dense_30[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1, 1, 8)      0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 4, 4, 8)      0           conv2d_49[0][0]                  \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 4, 4, 1)      0           multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 4, 4, 1)      0           multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4, 4, 2)      0           lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 1)      98          concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 4, 4, 8)      0           multiply_9[0][0]                 \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 128)          0           multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 64)           8256        flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 32)           2080        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Dense)               (None, 28)           924         dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 32)           928         embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 64)           2112        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 128)          8320        dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 4, 4, 8)      0           dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 8)      264         reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling2D) (None, 8, 8, 8)      0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 16)     1168        up_sampling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling2D) (None, 16, 16, 16)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 32)   4640        up_sampling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling2D) (None, 32, 32, 32)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 32, 64)   32832       up_sampling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling2D) (None, 64, 64, 64)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 64, 64, 3)    3075        up_sampling2d_20[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 231,840\n",
      "Trainable params: 231,840\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18746/18746 [==============================] - 63s 3ms/step - loss: 0.3217\n",
      "Epoch 2/30\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2614\n",
      "Epoch 3/30\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2557\n",
      "Epoch 4/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2539\n",
      "Epoch 5/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2531\n",
      "Epoch 6/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2529\n",
      "Epoch 7/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2528\n",
      "Epoch 8/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2527\n",
      "Epoch 9/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2526\n",
      "Epoch 10/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2525\n",
      "Epoch 11/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2525\n",
      "Epoch 12/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2524\n",
      "Epoch 13/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2524\n",
      "Epoch 14/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2522\n",
      "Epoch 15/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2521\n",
      "Epoch 16/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2521\n",
      "Epoch 17/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2520\n",
      "Epoch 18/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2519\n",
      "Epoch 19/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2518\n",
      "Epoch 20/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2517\n",
      "Epoch 21/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2517\n",
      "Epoch 22/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2516\n",
      "Epoch 23/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2515\n",
      "Epoch 24/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2515\n",
      "Epoch 25/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2515\n",
      "Epoch 26/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2514\n",
      "Epoch 27/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2514\n",
      "Epoch 28/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2513\n",
      "Epoch 29/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2513\n",
      "Epoch 30/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2512\n",
      "\n",
      " CAE TRAIN TIME: 1814.3488388061523\n",
      "Savemodel Done!\n",
      "\n",
      " TOTAL TIME: 1814.3490374088287\n",
      "Epoch 1/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2512\n",
      "Epoch 2/50\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2510\n",
      "Epoch 6/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2510\n",
      "Epoch 7/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2509\n",
      "Epoch 8/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2509\n",
      "Epoch 9/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2509\n",
      "Epoch 10/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2509\n",
      "Epoch 11/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2508\n",
      "Epoch 12/50\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2508\n",
      "Epoch 13/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2508\n",
      "Epoch 14/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2508\n",
      "Epoch 15/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 16/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2508\n",
      "Epoch 17/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 18/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 19/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 20/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 21/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 22/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 23/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 24/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 25/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 26/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 27/50\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2506\n",
      "Epoch 28/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 29/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 30/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 31/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 32/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 33/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 34/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 35/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 36/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 37/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 38/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 39/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 40/50\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2504\n",
      "Epoch 41/50\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2504\n",
      "Epoch 42/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 43/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 44/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 45/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 46/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "Epoch 47/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "Epoch 48/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "Epoch 49/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "Epoch 50/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "\n",
      " CAE TRAIN TIME: 4834.5274612903595\n",
      "Savemodel Done!\n",
      "\n",
      " TOTAL TIME: 4834.527659893036\n",
      "Epoch 1/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "Epoch 2/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "Epoch 3/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "Epoch 4/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "Epoch 5/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2503\n",
      "Epoch 6/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 7/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 8/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 9/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 10/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 11/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 12/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 13/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 14/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 15/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 16/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 17/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 18/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 19/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 20/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 21/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 22/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 23/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 24/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 25/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 26/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 27/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 28/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 29/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 30/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 31/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 32/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 33/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 34/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 35/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 36/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 37/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 38/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 39/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 40/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 41/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 42/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 43/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 44/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 45/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 46/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 47/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 48/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 49/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 50/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 51/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 52/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 53/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 54/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 55/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 56/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 57/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 58/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 59/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 60/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 61/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 62/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 63/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 64/70\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2499\n",
      "Epoch 65/70\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2499\n",
      "Epoch 66/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 67/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 68/70\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2499\n",
      "Epoch 69/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 70/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "\n",
      " CAE TRAIN TIME: 9047.295667648315\n",
      "Savemodel Done!\n",
      "\n",
      " TOTAL TIME: 9047.295866250992\n",
      "Epoch 1/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 2/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 3/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 4/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 5/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 6/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 7/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 8/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 9/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 10/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 11/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 12/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 13/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2499\n",
      "Epoch 14/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 15/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 16/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 17/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 18/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 19/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 20/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 21/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 22/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 23/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 24/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 25/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 26/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 27/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 28/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 29/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 30/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 31/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2498\n",
      "Epoch 32/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2498\n",
      "Epoch 33/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2498\n",
      "Epoch 34/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 35/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 37/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 38/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 39/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2498\n",
      "Epoch 40/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 41/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 42/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 43/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 44/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 45/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 46/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 47/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 48/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 49/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 50/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 51/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 52/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 53/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 54/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 55/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 56/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 57/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 58/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 59/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2497\n",
      "Epoch 60/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 61/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 62/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2497\n",
      "Epoch 63/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2497\n",
      "Epoch 64/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2497\n",
      "Epoch 65/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 66/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 67/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 68/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 69/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 70/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2497\n",
      "Epoch 71/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 72/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 73/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 74/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 75/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 76/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 77/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 78/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 79/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 80/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 81/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 82/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 83/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 84/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 85/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 86/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 87/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 88/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 89/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 90/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 91/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 92/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 93/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 94/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 95/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 96/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 97/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 98/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 99/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 100/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 101/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 102/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 103/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 104/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 105/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 106/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 107/150\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2496\n",
      "Epoch 108/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 109/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 110/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 111/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 112/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 113/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 114/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 115/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 116/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 117/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 118/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 119/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 120/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 121/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 122/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 123/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 124/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 125/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 126/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 127/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 128/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 129/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 130/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 131/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 132/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 133/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 134/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 135/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 136/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 137/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 138/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 139/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2495\n",
      "Epoch 140/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 141/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 142/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 143/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 144/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 145/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 146/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 147/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 148/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2495\n",
      "Epoch 149/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "Epoch 150/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2496\n",
      "\n",
      " CAE TRAIN TIME: 18083.829253911972\n",
      "Savemodel Done!\n",
      "\n",
      " TOTAL TIME: 18083.82945251465\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 64, 64, 128)  6272        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 128)          0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_6 (GlobalM (None, 128)          0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 1, 128)    0           global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 1, 128)    0           global_max_pooling2d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 1, 1, 16)     2064        reshape_16[0][0]                 \n",
      "                                                                 reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 1, 1, 128)    2176        dense_36[0][0]                   \n",
      "                                                                 dense_36[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1, 1, 128)    0           dense_37[0][0]                   \n",
      "                                                                 dense_37[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1, 1, 128)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 64, 64, 128)  0           conv2d_56[0][0]                  \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 64, 64, 1)    0           multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 64, 64, 1)    0           multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 2)    0           lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 64, 64, 1)    98          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 64, 64, 128)  0           multiply_11[0][0]                \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 32, 32, 128)  0           multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 64)   131136      max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 64)           0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_7 (GlobalM (None, 64)           0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1, 1, 64)     0           global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 1, 1, 64)     0           global_max_pooling2d_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 1, 1, 8)      520         reshape_18[0][0]                 \n",
      "                                                                 reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 1, 1, 64)     576         dense_38[0][0]                   \n",
      "                                                                 dense_38[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1, 1, 64)     0           dense_39[0][0]                   \n",
      "                                                                 dense_39[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1, 1, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 32, 32, 64)   0           conv2d_58[0][0]                  \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 32, 32, 1)    0           multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 32, 32, 1)    0           multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 2)    0           lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 1)    98          concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 32, 32, 64)   0           multiply_13[0][0]                \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 16, 16, 64)   0           multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 32)   18464       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 32)           0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_8 (GlobalM (None, 32)           0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 1, 1, 32)     0           global_average_pooling2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 1, 1, 32)     0           global_max_pooling2d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 1, 1, 4)      132         reshape_20[0][0]                 \n",
      "                                                                 reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 1, 1, 32)     160         dense_40[0][0]                   \n",
      "                                                                 dense_40[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1, 1, 32)     0           dense_41[0][0]                   \n",
      "                                                                 dense_41[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 1, 32)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 16, 16, 32)   0           conv2d_60[0][0]                  \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 16, 16, 1)    0           multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 16, 16, 1)    0           multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 2)    0           lambda_15[0][0]                  \n",
      "                                                                 lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 1)    98          concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 16, 16, 32)   0           multiply_15[0][0]                \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 8, 8, 32)     0           multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 16)     4624        max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 16)           0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_9 (GlobalM (None, 16)           0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 1, 1, 16)     0           global_average_pooling2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 1, 1, 16)     0           global_max_pooling2d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1, 1, 2)      34          reshape_22[0][0]                 \n",
      "                                                                 reshape_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 1, 1, 16)     48          dense_42[0][0]                   \n",
      "                                                                 dense_42[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1, 1, 16)     0           dense_43[0][0]                   \n",
      "                                                                 dense_43[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1, 1, 16)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 8, 8, 16)     0           conv2d_62[0][0]                  \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 8, 8, 1)      0           multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 8, 8, 1)      0           multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 8, 8, 2)      0           lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 1)      98          concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 8, 8, 16)     0           multiply_17[0][0]                \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 4, 4, 16)     0           multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 4, 4, 8)      520         max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 8)            0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_10 (Global (None, 8)            0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 1, 1, 8)      0           global_average_pooling2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 1, 1, 8)      0           global_max_pooling2d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 1, 1, 1)      9           reshape_24[0][0]                 \n",
      "                                                                 reshape_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1, 1, 8)      16          dense_44[0][0]                   \n",
      "                                                                 dense_44[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 1, 1, 8)      0           dense_45[0][0]                   \n",
      "                                                                 dense_45[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1, 1, 8)      0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 4, 4, 8)      0           conv2d_64[0][0]                  \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 4, 4, 1)      0           multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 4, 4, 1)      0           multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 4, 4, 2)      0           lambda_19[0][0]                  \n",
      "                                                                 lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 4, 4, 1)      98          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 4, 4, 8)      0           multiply_19[0][0]                \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 128)          0           multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 64)           8256        flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 32)           2080        dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Dense)               (None, 24)           792         dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 32)           800         embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 64)           2112        dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 128)          8320        dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)            (None, 4, 4, 8)      0           dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 4, 4, 8)      264         reshape_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling2D) (None, 8, 8, 8)      0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 16)     1168        up_sampling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling2D) (None, 16, 16, 16)   0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 32)   4640        up_sampling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling2D) (None, 32, 32, 32)   0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 64)   32832       up_sampling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling2D) (None, 64, 64, 64)   0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 64, 64, 3)    3075        up_sampling2d_24[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 231,580\n",
      "Trainable params: 231,580\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18746/18746 [==============================] - 63s 3ms/step - loss: 0.3252\n",
      "Epoch 2/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2643\n",
      "Epoch 3/30\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2563\n",
      "Epoch 4/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2543\n",
      "Epoch 5/30\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2534\n",
      "Epoch 6/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2530\n",
      "Epoch 7/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2528\n",
      "Epoch 8/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2527\n",
      "Epoch 9/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2525\n",
      "Epoch 10/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2524\n",
      "Epoch 12/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2523\n",
      "Epoch 13/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2522\n",
      "Epoch 14/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2522\n",
      "Epoch 15/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2521\n",
      "Epoch 16/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2520\n",
      "Epoch 17/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2520\n",
      "Epoch 18/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2520\n",
      "Epoch 19/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2518\n",
      "Epoch 20/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2518\n",
      "Epoch 21/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2517\n",
      "Epoch 22/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2518\n",
      "Epoch 23/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2517\n",
      "Epoch 24/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2516\n",
      "Epoch 25/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2516\n",
      "Epoch 26/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2515\n",
      "Epoch 27/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2515\n",
      "Epoch 28/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2515\n",
      "Epoch 29/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2514\n",
      "Epoch 30/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2514\n",
      "\n",
      " CAE TRAIN TIME: 19898.88502717018\n",
      "Savemodel Done!\n",
      "\n",
      " TOTAL TIME: 19898.885225772858\n",
      "Epoch 1/50\n",
      "17280/18746 [==========================>...] - ETA: 4s - loss: 0.2514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 34/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 35/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 36/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 37/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 38/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 39/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 40/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 41/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 42/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 43/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 44/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 45/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 46/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 47/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 48/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 49/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 50/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "\n",
      " CAE TRAIN TIME: 22914.586727142334\n",
      "Savemodel Done!\n",
      "\n",
      " TOTAL TIME: 22914.58692574501\n",
      "Epoch 1/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 2/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2505\n",
      "Epoch 3/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 4/70\n",
      "  128/18746 [..............................] - ETA: 1:00 - loss: 0.2490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 36/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 37/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 38/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 39/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 40/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 41/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 42/70\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2502\n",
      "Epoch 43/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2502\n",
      "Epoch 44/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 45/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 46/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 47/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 48/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 49/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 50/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 51/70\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2501\n",
      "Epoch 52/70\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2501\n",
      "Epoch 53/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 54/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2501\n",
      "Epoch 55/70\n",
      "17408/18746 [==========================>...] - ETA: 4s - loss: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 15/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 16/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 17/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 18/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 19/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 20/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 21/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 22/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 23/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 24/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 25/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 26/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 27/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 28/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 29/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 30/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 31/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 32/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2500\n",
      "Epoch 33/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 34/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 35/150\n",
      " 2432/18746 [==>...........................] - ETA: 52s - loss: 0.2478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 67/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 68/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 69/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 70/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 71/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 72/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 73/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 74/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2499\n",
      "Epoch 75/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 76/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 77/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 78/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 79/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 80/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 81/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 82/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 83/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 84/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 85/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 86/150\n",
      "15232/18746 [=======================>......] - ETA: 11s - loss: 0.2496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2498\n",
      "Epoch 119/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 120/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 121/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 122/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 123/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 124/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 125/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 126/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 127/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 128/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 129/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2498\n",
      "Epoch 130/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 131/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 132/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 133/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 134/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 135/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 136/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 137/150\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2497\n",
      "Epoch 138/150\n",
      " 8960/18746 [=============>................] - ETA: 31s - loss: 0.2499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2518\n",
      "Epoch 21/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2517\n",
      "Epoch 22/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2517\n",
      "Epoch 23/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2516\n",
      "Epoch 24/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2516\n",
      "Epoch 25/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2515\n",
      "Epoch 26/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2515\n",
      "Epoch 27/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2514\n",
      "Epoch 28/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2514\n",
      "Epoch 29/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2514\n",
      "Epoch 30/30\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2514\n",
      "\n",
      " CAE TRAIN TIME: 37962.60775208473\n",
      "Savemodel Done!\n",
      "\n",
      " TOTAL TIME: 37962.60795068741\n",
      "Epoch 1/50\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2513\n",
      "Epoch 2/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2512\n",
      "Epoch 3/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2513\n",
      "Epoch 4/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2513\n",
      "Epoch 5/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2512\n",
      "Epoch 6/50\n",
      "18746/18746 [==============================] - 61s 3ms/step - loss: 0.2512\n",
      "Epoch 7/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2512\n",
      "Epoch 8/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      " 6528/18746 [=========>....................] - ETA: 39s - loss: 0.2515"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2508\n",
      "Epoch 42/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2508\n",
      "Epoch 43/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2508\n",
      "Epoch 44/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2508\n",
      "Epoch 45/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 46/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2508\n",
      "Epoch 47/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 48/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 49/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 50/50\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "\n",
      " CAE TRAIN TIME: 40982.25586938858\n",
      "Savemodel Done!\n",
      "\n",
      " TOTAL TIME: 40982.25606799126\n",
      "Epoch 1/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 2/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 3/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 4/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 5/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 6/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 7/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 8/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2506\n",
      "Epoch 9/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 10/70\n",
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2507\n",
      "Epoch 11/70\n",
      "18688/18746 [============================>.] - ETA: 0s - loss: 0.2506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18746/18746 [==============================] - 60s 3ms/step - loss: 0.2504\n",
      "Epoch 44/70\n",
      " 2816/18746 [===>..........................] - ETA: 50s - loss: 0.2508"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import callbacks, optimizers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.io import fits\n",
    "from skimage import exposure\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, GlobalAveragePooling2D, multiply\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "import time\n",
    "Tstart = time.time() #Timer start\n",
    "\n",
    "\n",
    "def getdate():\n",
    "    import datetime\n",
    "    import time\n",
    "    year=str(datetime.datetime.now().year)\n",
    "    month=str(datetime.datetime.now().month)\n",
    "    day=str(datetime.datetime.now().day)\n",
    "    time=str(time.time())\n",
    "    #print(year+'-'+month+'-'+day+'-'+time)\n",
    "    return(year+'-'+month+'-'+day+'-'+time)\n",
    "## MODEL PRE-SETTING ##\n",
    "\n",
    "\n",
    "def cae(embedding_fea):\n",
    "    input_img = Input(shape=(64, 64, 3))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "    x = Conv2D(128, (4, 4), activation='relu', padding='same')(input_img) #(64,64,128)\n",
    "    x = cbam(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) #(32, 32, 128)\n",
    "    x = Conv2D(64, (4, 4), activation='relu', padding='same')(x) #(32, 32, 64)\n",
    "    x = cbam(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) #(16, 16, 64)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x) #(16, 16, 32)\n",
    "    x = cbam(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) #(8, 8, 32)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x) #(8, 8, 16)\n",
    "    x = cbam(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x) #(4, 4, 16)\n",
    "    x = Conv2D(8, (2, 2), activation='relu', padding='same')(x) #(4, 4, 8)\n",
    "    x = cbam(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=64, activation='relu')(x)\n",
    "    x = Dense(units=32, activation='relu')(x)\n",
    "#     x = Dense(units=16, activation='relu')(x)\n",
    "    encoded = Dense(units=embedding_fea, activation='relu', name='embedding')(x)\n",
    "#     x = Dense(units=16, activation='relu')(encoded)\n",
    "    x = Dense(units=32, activation='relu')(encoded)\n",
    "    x = Dense(units=64, activation='relu')(x)\n",
    "    x = Dense(units=128, activation='relu')(x)\n",
    "    x = Reshape((4, 4, 8))(x)\n",
    "\n",
    "    x = Conv2D(8, (2, 2), activation='relu', padding='same')(x) #(4, 4, 8)\n",
    "    x = UpSampling2D((2, 2))(x) #(8, 8, 8)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x) #(8, 8, 16)\n",
    "    x = UpSampling2D((2, 2))(x) #(16, 16, 16)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x) #(16, 16, 32)\n",
    "    x = UpSampling2D((2, 2))(x) #(32, 32, 32)\n",
    "    x = Conv2D(64, (4, 4), activation='relu',padding = 'same')(x) #(30, 30, 64)\n",
    "    x = UpSampling2D((2, 2))(x) #(64, 64, 64)\n",
    "    decoded = Conv2D(3, (4, 4), activation='sigmoid',padding = 'same')(x) #(64, 64, 128)\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    optimizer_adam = optimizers.Adam(lr=0.001)\n",
    "    autoencoder.compile(optimizer=optimizer_adam, loss='binary_crossentropy')\n",
    "\n",
    "    print(autoencoder.summary())\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "def cbam(cbam_feature, ratio=8):\n",
    "\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    return cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "\n",
    "    #channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    #channel = input_feature._keras_shape[-1]\n",
    "    channel = input_feature.shape.as_list()[-1]\n",
    "\n",
    "    shared_layer_one = Dense(channel//ratio, activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel, kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "    avg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "    #assert avg_pool._keras_shape[1:] == (1,1,channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    #assert avg_pool._keras_shape[1:] == (1,1,channel//ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    #assert avg_pool._keras_shape[1:] == (1,1,channel)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1,1,channel))(max_pool)\n",
    "    #assert max_pool._keras_shape[1:] == (1,1,channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    #assert max_pool._keras_shape[1:] == (1,1,channel//ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    #assert max_pool._keras_shape[1:] == (1,1,channel)\n",
    "\n",
    "    cbam_feature = Add()([avg_pool,max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    '''\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    '''\n",
    "\n",
    "    return Multiply()([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "    kernel_size = 7\n",
    "    '''\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature._keras_shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature._keras_shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "    '''\n",
    "    #channel = input_feature._keras_shape[-1]\n",
    "    channel = input_feature.shape.as_list()[-1]\n",
    "    cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool._keras_shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool._keras_shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat._keras_shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters = 1,kernel_size=kernel_size,strides=1,padding='same',activation='sigmoid',kernel_initializer='he_normal',use_bias=False)(concat)\t\n",
    "    assert cbam_feature._keras_shape[-1] == 1\n",
    "\n",
    "    '''\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    '''\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "\n",
    "def savemodel(savename):\n",
    "    autoencoder.save(savename + getdate() + '.h5')\n",
    "    print('Savemodel Done!')\n",
    "\n",
    "def plot_reconstruction():\n",
    "    decoded_imgs = autoencoder.predict(image_c) \n",
    "    n = 6\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(image_c[i].reshape(64, 64))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction|\n",
    "        ax = plt.subplot(2, n, i+1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(64, 64))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.savefig(savename + '.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "############################################### \n",
    "# preprocess parameter\n",
    "###############################################\n",
    "  \n",
    "    samnum = None\n",
    "\n",
    "    Time1 = time.time()\n",
    "    #X_train = dataprocess(datapath, samnum)\n",
    "    Time2=time.time()\n",
    "    print('\\n', 'DATA PROCESS TIME:', Time2-Time1)\n",
    "\n",
    "###########################################\n",
    "#  model parameter\n",
    "###########################################\n",
    "    batchsize = 128\n",
    "    Epochs = [30, 50,70,150]\n",
    "    Embedding_fea = [28,24,20,16]\n",
    "    embedding_floor = 83\n",
    "\n",
    "    Time3 = time.time()\n",
    "    for embedding_fea in Embedding_fea:\n",
    "        autoencoder = cae(embedding_fea)\n",
    "        print(embedding_fea)\n",
    "        Epochtmp = 0\n",
    "        for epoch in Epochs:\n",
    "            Epochtmp+=epoch\n",
    "            autoencoder.fit(image_c, image_c, batch_size=batchsize, epochs=epoch, shuffle=True)\n",
    "            Time4 = time.time()\n",
    "            print('\\n', 'CAE TRAIN TIME:', Time4-Time3)\n",
    "            savename = 'CAE_cbam(smooth-16874)<-inlier with outlier-> (edge&cigar-1295&579)/RGB_%depoch%dfea%dF'%(Epochtmp, embedding_fea, embedding_floor)\n",
    "            savemodel(savename)\n",
    "#             plot_reconstruction()\n",
    "            print('\\n', 'TOTAL TIME:', Time4-Time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
